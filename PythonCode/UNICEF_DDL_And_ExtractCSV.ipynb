{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a48e29",
   "metadata": {},
   "source": [
    "# Create Tables and Materialized Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c7d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: postgres\n",
      "Enter password: ········\n",
      "DDL Executed Successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "try:\n",
    "    with psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=input(\"Enter username: \"),\n",
    "        password=getpass(\"Enter password: \"),\n",
    "        database = \"UNICEF\"\n",
    "    ) as connection:\n",
    "        \n",
    "        create_table_Year_Dimension = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS public.\"Year_Dimension\"\n",
    "            (\n",
    "            \"Year_ID\" INT NOT NULL,\n",
    "            \"Data_Year\" VARCHAR(100),\n",
    "            CONSTRAINT \"Year_ID_pkey\" PRIMARY KEY (\"Year_ID\")\n",
    "            )\n",
    "        \"\"\"\n",
    "        create_table_Source_Dimension = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS public.\"Source_Dimension\"\n",
    "            (\n",
    "            \"Source_ID\" INT NOT NULL,\n",
    "            \"Source_Type\" VARCHAR(100),\n",
    "            \"Source_Desc\" VARCHAR(100),\n",
    "            CONSTRAINT \"Source_ID_pkey\" PRIMARY KEY (\"Source_ID\")\n",
    "            )\n",
    "        \"\"\"\n",
    "        create_table_Indicator_Dimension = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS public.\"Indicator_Dimension\"\n",
    "            (\n",
    "            \"Indicator_ID\" INT NOT NULL,\n",
    "            \"Indicator_Type\" VARCHAR(100) NOT NULL,\n",
    "            \"Indicator_Desc\" VARCHAR(100) NULL,\n",
    "            CONSTRAINT \"Indicator_Dimension_pkey\" PRIMARY KEY (\"Indicator_ID\")\n",
    "            )\n",
    "        \"\"\"  \n",
    "        create_table_Location_Dimension = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS public.\"Location_Dimension\"\n",
    "            (\n",
    "            \"Location_ID\" SERIAL NOT NULL,\n",
    "            \"ISOCode\" VARCHAR(10) NOT NULL,\n",
    "            \"CountryAndAreaName\" VARCHAR(100) NOT NULL,\n",
    "            \"RegionName\" VARCHAR(100),\n",
    "            \"DevlopmentStage\" VARCHAR(100),\n",
    "            CONSTRAINT \"Location_Dimension_plockey\" PRIMARY KEY (\"Location_ID\")\n",
    "            )\n",
    "        \"\"\"\n",
    "        create_table_ICT_Skillset_Fact = \"\"\"\n",
    "           CREATE TABLE IF NOT EXISTS public.\"ICT_Skillset_Fact\"\n",
    "            (\n",
    "            \"Skillset_Fact_ID\" SERIAL NOT NULL,\n",
    "            \"Location_ID\" INT NOT NULL,\n",
    "            \"Indicator_ID\" INT NOT NULL,\n",
    "            \"Source_ID\" INT NOT NULL,\n",
    "            \"Year_ID\" INT NOT NULL,\n",
    "            \"Sex\" VARCHAR(10),\n",
    "            \"Moved_File\" FLOAT,\n",
    "            \"Copy_Paste\" FLOAT,\n",
    "            \"Sent_Email\" FLOAT,\n",
    "            \"Used_Excel\" FLOAT,\n",
    "            \"Installed_Hardware\" FLOAT,\n",
    "            \"Installed_Software\" FLOAT,\n",
    "            \"Created_PPT\" FLOAT,\n",
    "            \"Transferred_File\" FLOAT,\n",
    "            \"Knows_Programming\" FLOAT,\n",
    "            \"Atleast_One_Skill_Total\" FLOAT,\n",
    "            \"Atleast_One_Skill_Rural\" FLOAT,\n",
    "            \"Atleast_One_Skill_Urban\" FLOAT,\n",
    "            \"Atleast_One_Skill_Poorest\" FLOAT,\n",
    "            \"Atleast_One_Skill_Richest\" FLOAT,\n",
    "            CONSTRAINT \"ICT_Skillset_pkey\" PRIMARY KEY (\"Skillset_Fact_ID\"),\n",
    "            CONSTRAINT \"Location_Dimension_ICTfkey\" FOREIGN KEY(\"Location_ID\") REFERENCES public.\"Location_Dimension\"(\"Location_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Indicator_ICTfkey\" FOREIGN KEY(\"Indicator_ID\") REFERENCES public.\"Indicator_Dimension\"(\"Indicator_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Source_ICTfkey\" FOREIGN KEY(\"Source_ID\") REFERENCES public.\"Source_Dimension\"(\"Source_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Year_ICTfkey\" FOREIGN KEY(\"Year_ID\") REFERENCES public.\"Year_Dimension\"(\"Year_ID\") ON UPDATE CASCADE\n",
    "            )\n",
    "        \"\"\"   \n",
    "        create_table_Education_Fact = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS public.\"Education_Fact\"\n",
    "            (\n",
    "            \"Education_Fact_ID\" SERIAL NOT NULL,\n",
    "            \"Location_ID\" INT NOT NULL,\n",
    "            \"Indicator_ID\" INT NOT NULL,\n",
    "            \"Source_ID\" INT NOT NULL,\n",
    "            \"Year_ID\" INT NOT NULL,\n",
    "            \"Total\" FLOAT,\n",
    "            \"Female\" FLOAT,\n",
    "            \"Male\" FLOAT,\n",
    "            \"Urban\" FLOAT,\n",
    "            \"Rural\" FLOAT,\n",
    "            \"Poorest\" FLOAT,\n",
    "            \"Second\" FLOAT,\n",
    "            \"Middle\" FLOAT,\n",
    "            \"Fourth\" FLOAT,\n",
    "            \"Richest\" FLOAT,\n",
    "            CONSTRAINT \"Education_Fact_pkey\" PRIMARY KEY (\"Education_Fact_ID\"),\n",
    "            CONSTRAINT \"Location_Dimension_EDfkey\" FOREIGN KEY(\"Location_ID\") REFERENCES public.\"Location_Dimension\"(\"Location_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Indicator_EDfkey\" FOREIGN KEY(\"Indicator_ID\") REFERENCES public.\"Indicator_Dimension\"(\"Indicator_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Source_EDfkey\" FOREIGN KEY(\"Source_ID\") REFERENCES public.\"Source_Dimension\"(\"Source_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Year_EDfkey\" FOREIGN KEY(\"Year_ID\") REFERENCES public.\"Year_Dimension\"(\"Year_ID\") ON UPDATE CASCADE\n",
    "            )\n",
    "        \"\"\" \n",
    "        create_table_Death_Mortality_WASH_Fact = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS public.\"Death_Mortality_WASH_Fact\"\n",
    "            (\n",
    "            \"Fact_ID\" SERIAL NOT NULL,\n",
    "            \"Location_ID\" INT NOT NULL,\n",
    "            \"Indicator_ID\" INT NOT NULL,\n",
    "            \"Source_ID\" INT NOT NULL,\n",
    "            \"Year_ID\" INT NOT NULL,\n",
    "            \"Obs_Value\" FLOAT,\n",
    "            CONSTRAINT \"Fact_ID_pkey\" PRIMARY KEY (\"Fact_ID\"),\n",
    "            CONSTRAINT \"Location_Dimension_DMfkey\" FOREIGN KEY(\"Location_ID\") REFERENCES public.\"Location_Dimension\"(\"Location_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Indicator_BMfkey\" FOREIGN KEY(\"Indicator_ID\") REFERENCES public.\"Indicator_Dimension\"(\"Indicator_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Source_DMfkey\" FOREIGN KEY(\"Source_ID\") REFERENCES public.\"Source_Dimension\"(\"Source_ID\") ON UPDATE CASCADE,\n",
    "            CONSTRAINT \"Year_DMfkey\" FOREIGN KEY(\"Year_ID\") REFERENCES public.\"Year_Dimension\"(\"Year_ID\") ON UPDATE CASCADE\n",
    "            )\n",
    "        \"\"\" \n",
    "        create_table_Death_Mortality_WASH_Fact_View = \"\"\"\n",
    "            CREATE MATERIALIZED VIEW  IF NOT EXISTS Death_Mortality_WASH_Fact_View AS \n",
    "            select \"Death_Mortality_WASH_Fact\".*,\"Location_Dimension\".\"ISOCode\", \"Location_Dimension\".\"CountryAndAreaName\",\"Location_Dimension\".\"RegionName\",\"Location_Dimension\".\"DevlopmentStage\",\n",
    "            \"Indicator_Dimension\".\"Indicator_Type\",\"Year_Dimension\".\"Data_Year\",\"Source_Dimension\".\"Source_Type\",\"Source_Dimension\".\"Source_Desc\"\n",
    "            from public.\"Death_Mortality_WASH_Fact\",public.\"Location_Dimension\",public.\"Indicator_Dimension\",public.\"Year_Dimension\",public.\"Source_Dimension\"\n",
    "            where  \"Death_Mortality_WASH_Fact\".\"Location_ID\" = \"Location_Dimension\".\"Location_ID\"\n",
    "            and \"Death_Mortality_WASH_Fact\".\"Year_ID\" = \"Year_Dimension\".\"Year_ID\"\n",
    "            and \"Death_Mortality_WASH_Fact\".\"Source_ID\" = \"Source_Dimension\".\"Source_ID\"\n",
    "            and \"Death_Mortality_WASH_Fact\".\"Indicator_ID\" = \"Indicator_Dimension\".\"Indicator_ID\"\n",
    "        \"\"\" \n",
    "        create_table_ICT_Skillset_Fact_View = \"\"\"\n",
    "            CREATE MATERIALIZED VIEW  IF NOT EXISTS ICT_Skillset_Fact_View AS \n",
    "            select \"ICT_Skillset_Fact\".*,\"Location_Dimension\".\"ISOCode\", \"Location_Dimension\".\"CountryAndAreaName\",\"Location_Dimension\".\"RegionName\",\"Location_Dimension\".\"DevlopmentStage\",\n",
    "            \"Indicator_Dimension\".\"Indicator_Type\",\"Year_Dimension\".\"Data_Year\",\"Source_Dimension\".\"Source_Type\",\"Source_Dimension\".\"Source_Desc\"\n",
    "            from public.\"ICT_Skillset_Fact\",public.\"Location_Dimension\",public.\"Indicator_Dimension\",public.\"Year_Dimension\",public.\"Source_Dimension\"\n",
    "            where  \"ICT_Skillset_Fact\".\"Location_ID\" = \"Location_Dimension\".\"Location_ID\"\n",
    "            and \"ICT_Skillset_Fact\".\"Year_ID\" = \"Year_Dimension\".\"Year_ID\"\n",
    "            and \"ICT_Skillset_Fact\".\"Source_ID\" = \"Source_Dimension\".\"Source_ID\"\n",
    "            and \"ICT_Skillset_Fact\".\"Indicator_ID\" = \"Indicator_Dimension\".\"Indicator_ID\"\n",
    "        \"\"\" \n",
    "        create_table_Education_Fact_View = \"\"\"\n",
    "           CREATE MATERIALIZED VIEW  IF NOT EXISTS Education_Fact_View AS \n",
    "           select \"Education_Fact\".*,\"Location_Dimension\".\"ISOCode\", \"Location_Dimension\".\"CountryAndAreaName\",\"Location_Dimension\".\"RegionName\",\"Location_Dimension\".\"DevlopmentStage\",\n",
    "           \"Indicator_Dimension\".\"Indicator_Type\",\"Year_Dimension\".\"Data_Year\",\"Source_Dimension\".\"Source_Type\",\"Source_Dimension\".\"Source_Desc\"\n",
    "           from public.\"Education_Fact\",public.\"Location_Dimension\",public.\"Indicator_Dimension\",public.\"Year_Dimension\",public.\"Source_Dimension\"\n",
    "           where  \"Education_Fact\".\"Location_ID\" = \"Location_Dimension\".\"Location_ID\"\n",
    "           and \"Education_Fact\".\"Year_ID\" = \"Year_Dimension\".\"Year_ID\"\n",
    "           and \"Education_Fact\".\"Source_ID\" = \"Source_Dimension\".\"Source_ID\"\n",
    "           and \"Education_Fact\".\"Indicator_ID\" = \"Indicator_Dimension\".\"Indicator_ID\"\n",
    "        \"\"\" \n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(create_table_Year_Dimension)\n",
    "            cursor.execute(create_table_Source_Dimension)\n",
    "            cursor.execute(create_table_Indicator_Dimension)\n",
    "            cursor.execute(create_table_Location_Dimension)\n",
    "            cursor.execute(create_table_ICT_Skillset_Fact)\n",
    "            cursor.execute(create_table_Education_Fact)\n",
    "            cursor.execute(create_table_Death_Mortality_WASH_Fact)\n",
    "            cursor.execute(create_table_Death_Mortality_WASH_Fact_View)\n",
    "            cursor.execute(create_table_ICT_Skillset_Fact_View)\n",
    "            cursor.execute(create_table_Education_Fact_View)\n",
    "            connection.commit()\n",
    "            print(\"DDL Executed Successfully\")\n",
    "except BaseException as e:\n",
    "    connection.rollback()\n",
    "    print(\"DDL Execution Aborted\")\n",
    "    print(e)\n",
    "    \n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0532bf",
   "metadata": {},
   "source": [
    "# Insert Rows from CSV into Dimension Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b078821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: postgres\n",
      "Enter password: ········\n",
      "Indicator Dimension Table rows added successfully\n",
      "Year Dimension Table rows added successfully\n",
      "Source Dimension Table rows added successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from getpass import getpass\n",
    "import pandas as pnd\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Import Indicator Dimension CSV files into dataframe\n",
    "    data_Indicator = pnd.read_csv(os.getcwd()+'/Indicator_Dimension.csv')\n",
    "    df_Indicator = pnd.DataFrame(data_Indicator)\n",
    "    with psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=input(\"Enter username: \"),\n",
    "        password=getpass(\"Enter password: \"),\n",
    "        database = \"UNICEF\"\n",
    "    ) as connection:\n",
    "        for row_loc in df_Indicator.itertuples():\n",
    "            with connection.cursor() as cursor:\n",
    "                add_loc = (\"INSERT INTO public.\\\"Indicator_Dimension\\\" VALUES (%s,%s,%s)\")\n",
    "                data_loc = (row_loc.Indicator_ID, row_loc.Indicator_Type, row_loc.Indicator_Desc)\n",
    "                cursor.execute(add_loc, data_loc)\n",
    "                connection.commit()  \n",
    "        print(\"Indicator Dimension Table rows added successfully\")\n",
    "        \n",
    "        data_Year = pnd.read_csv(os.getcwd()+'/Year_Dimension.csv')\n",
    "        df_Year = pnd.DataFrame(data_Year)\n",
    "        for row_loc in df_Year.itertuples():\n",
    "            with connection.cursor() as cursor:\n",
    "                add_loc = (\"INSERT INTO public.\\\"Year_Dimension\\\" VALUES (%s,%s)\")\n",
    "                data_loc = (row_loc.Year_ID, row_loc.Data_Year)\n",
    "                cursor.execute(add_loc, data_loc)\n",
    "                connection.commit()  \n",
    "        print(\"Year Dimension Table rows added successfully\")\n",
    "        \n",
    "        data_Source = pnd.read_csv(os.getcwd()+'/Sourc_Dimension.csv')\n",
    "        df_Source = pnd.DataFrame(data_Source)\n",
    "        for row_loc in df_Source.itertuples():\n",
    "            with connection.cursor() as cursor:\n",
    "                add_loc = (\"INSERT INTO public.\\\"Source_Dimension\\\" VALUES (%s,%s,%s)\")\n",
    "                data_loc = (row_loc.ID, row_loc.Source_Type, row_loc.Desc)\n",
    "                cursor.execute(add_loc, data_loc)\n",
    "                connection.commit()  \n",
    "        print(\"Source Dimension Table rows added successfully\")\n",
    "        \n",
    "except BaseException as e:\n",
    "    connection.rollback()\n",
    "    print(e)\n",
    "    \n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50f9e7",
   "metadata": {},
   "source": [
    "# Export Data into CSV files to use in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a6fce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: postgres\n",
      "Enter password: ········\n",
      "File created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import psycopg2\n",
    "from getpass import getpass\n",
    "\n",
    "# Define CSV File path and Name\n",
    "CSVOutputfilePath = os.getcwd()+'/'\n",
    "CSVOutputfileName = 'Death_And_WASH.csv'\n",
    "connect_postgres = None\n",
    "\n",
    "# If the file path exists then\n",
    "if os.path.exists(CSVOutputfilePath):\n",
    "    try:\n",
    "        # Connect to postgres UNICEF database.\n",
    "        connect_postgres = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user= input(\"Enter username: \"),\n",
    "        password= getpass(\"Enter password: \"),\n",
    "        database = \"UNICEF\"\n",
    "        )\n",
    "\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(\"Connected to Database.\")\n",
    "        quit()\n",
    "\n",
    "    data_cursor = connect_postgres.cursor()\n",
    "\n",
    "    # Select Death_Mortality_WASH_Fact with rollup and grouping identifiers.\n",
    "    sqlSelectData = \"\"\"select \"Death_Mortality_WASH_Fact\".*,\"Location_Dimension\".\"ISOCode\", \"Location_Dimension\".\"CountryAndAreaName\",\"Location_Dimension\".\"RegionName\",\"Location_Dimension\".\"DevlopmentStage\",\n",
    "                    \"Indicator_Dimension\".\"Indicator_Type\",\"Year_Dimension\".\"Data_Year\",\"Source_Dimension\".\"Source_Type\",\"Source_Dimension\".\"Source_Desc\"\n",
    "                    from public.\"Death_Mortality_WASH_Fact\",public.\"Location_Dimension\",public.\"Indicator_Dimension\",public.\"Year_Dimension\",public.\"Source_Dimension\"\n",
    "                    where  \"Death_Mortality_WASH_Fact\".\"Location_ID\" = \"Location_Dimension\".\"Location_ID\"\n",
    "                    and \"Death_Mortality_WASH_Fact\".\"Year_ID\" = \"Year_Dimension\".\"Year_ID\"\n",
    "                    and \"Death_Mortality_WASH_Fact\".\"Source_ID\" = \"Source_Dimension\".\"Source_ID\"\n",
    "                    and \"Death_Mortality_WASH_Fact\".\"Indicator_ID\" = \"Indicator_Dimension\".\"Indicator_ID\"\n",
    "                    \"\"\"   \n",
    "    try:\n",
    "        data_cursor.execute(sqlSelectData)\n",
    "        resultData = data_cursor.fetchall()\n",
    "        headers_Row = [row_num[0] for row_num in data_cursor.description]\n",
    "\n",
    "        # Open the output CSV file for writing.\n",
    "        OutputcsvFile = csv.writer(open(CSVOutputfilePath + CSVOutputfileName, 'w', newline=''),\n",
    "                             delimiter=',', lineterminator='\\r\\n',\n",
    "                             quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "\n",
    "        # Adding header row and SQL data to the CSV file.\n",
    "        OutputcsvFile.writerow(headers_Row)\n",
    "        OutputcsvFile.writerows(resultData)\n",
    "        #print(resultData)\n",
    "        print(\"File created successfully.\")\n",
    "\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(\"File creation unsuccessful.\")\n",
    "        quit()\n",
    "\n",
    "    finally:\n",
    "        connect_postgres.close()\n",
    "\n",
    "else:\n",
    "    print(\"File creation unsuccessful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73503bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: postgres\n",
      "Enter password: ········\n",
      "File created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import psycopg2\n",
    "from getpass import getpass\n",
    "\n",
    "# Define CSV File path and Name\n",
    "CSVOutputfilePath = os.getcwd()+'/'\n",
    "CSVOutputfileName = 'ICT_Skillset.csv'\n",
    "connect_postgres = None\n",
    "\n",
    "# If the file path exists then\n",
    "if os.path.exists(CSVOutputfilePath):\n",
    "    try:\n",
    "        # Connect to postgres UNICEF database.\n",
    "        connect_postgres = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user= input(\"Enter username: \"),\n",
    "        password= getpass(\"Enter password: \"),\n",
    "        database = \"UNICEF\"\n",
    "        )\n",
    "\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(\"Connected to Database.\")\n",
    "        quit()\n",
    "\n",
    "    data_cursor = connect_postgres.cursor()\n",
    "\n",
    "    # Select Death_Mortality_WASH_Fact with rollup and grouping identifiers.\n",
    "    sqlSelectData = \"\"\"select \"ICT_Skillset_Fact\".*,\"Location_Dimension\".\"ISOCode\", \"Location_Dimension\".\"CountryAndAreaName\",\"Location_Dimension\".\"RegionName\",\"Location_Dimension\".\"DevlopmentStage\",\n",
    "                    \"Indicator_Dimension\".\"Indicator_Type\",\"Year_Dimension\".\"Data_Year\",\"Source_Dimension\".\"Source_Type\",\"Source_Dimension\".\"Source_Desc\"\n",
    "                    from public.\"ICT_Skillset_Fact\",public.\"Location_Dimension\",public.\"Indicator_Dimension\",public.\"Year_Dimension\",public.\"Source_Dimension\"\n",
    "                    where  \"ICT_Skillset_Fact\".\"Location_ID\" = \"Location_Dimension\".\"Location_ID\"\n",
    "                    and \"ICT_Skillset_Fact\".\"Year_ID\" = \"Year_Dimension\".\"Year_ID\"\n",
    "                    and \"ICT_Skillset_Fact\".\"Source_ID\" = \"Source_Dimension\".\"Source_ID\"\n",
    "                    and \"ICT_Skillset_Fact\".\"Indicator_ID\" = \"Indicator_Dimension\".\"Indicator_ID\"\n",
    "                    \"\"\"   \n",
    "    try:\n",
    "        data_cursor.execute(sqlSelectData)\n",
    "        resultData = data_cursor.fetchall()\n",
    "        headers_Row = [row_num[0] for row_num in data_cursor.description]\n",
    "\n",
    "        # Open the output CSV file for writing.\n",
    "        OutputcsvFile = csv.writer(open(CSVOutputfilePath + CSVOutputfileName, 'w', newline=''),\n",
    "                             delimiter=',', lineterminator='\\r\\n',\n",
    "                             quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "\n",
    "        # Adding header row and SQL data to the CSV file.\n",
    "        OutputcsvFile.writerow(headers_Row)\n",
    "        OutputcsvFile.writerows(resultData)\n",
    "        #print(resultData)\n",
    "        print(\"File created successfully.\")\n",
    "\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(\"File creation unsuccessful.\")\n",
    "        quit()\n",
    "\n",
    "    finally:\n",
    "        connect_postgres.close()\n",
    "\n",
    "else:\n",
    "    print(\"File creation unsuccessful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8192221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter username: postgres\n",
      "Enter password: ········\n",
      "File created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import psycopg2\n",
    "from getpass import getpass\n",
    "\n",
    "# Define CSV File path and Name\n",
    "CSVOutputfilePath = os.getcwd()+'/'\n",
    "CSVOutputfileName = 'Education_Facts.csv'\n",
    "connect_postgres = None\n",
    "\n",
    "# If the file path exists then\n",
    "if os.path.exists(CSVOutputfilePath):\n",
    "    try:\n",
    "        # Connect to postgres UNICEF database.\n",
    "        connect_postgres = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user= input(\"Enter username: \"),\n",
    "        password= getpass(\"Enter password: \"),\n",
    "        database = \"UNICEF\"\n",
    "        )\n",
    "\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(\"Connected to Database.\")\n",
    "        quit()\n",
    "\n",
    "    data_cursor = connect_postgres.cursor()\n",
    "\n",
    "    # Select Death_Mortality_WASH_Fact with rollup and grouping identifiers.\n",
    "    sqlSelectData = \"\"\"select \"Education_Fact\".*,\"Location_Dimension\".\"ISOCode\", \"Location_Dimension\".\"CountryAndAreaName\",\"Location_Dimension\".\"RegionName\",\"Location_Dimension\".\"DevlopmentStage\",\n",
    "                    \"Indicator_Dimension\".\"Indicator_Type\",\"Year_Dimension\".\"Data_Year\",\"Source_Dimension\".\"Source_Type\",\"Source_Dimension\".\"Source_Desc\"\n",
    "                    from public.\"Education_Fact\",public.\"Location_Dimension\",public.\"Indicator_Dimension\",public.\"Year_Dimension\",public.\"Source_Dimension\"\n",
    "                    where  \"Education_Fact\".\"Location_ID\" = \"Location_Dimension\".\"Location_ID\"\n",
    "                    and \"Education_Fact\".\"Year_ID\" = \"Year_Dimension\".\"Year_ID\"\n",
    "                    and \"Education_Fact\".\"Source_ID\" = \"Source_Dimension\".\"Source_ID\"\n",
    "                    and \"Education_Fact\".\"Indicator_ID\" = \"Indicator_Dimension\".\"Indicator_ID\"\n",
    "                    \"\"\"   \n",
    "    try:\n",
    "        data_cursor.execute(sqlSelectData)\n",
    "        resultData = data_cursor.fetchall()\n",
    "        headers_Row = [row_num[0] for row_num in data_cursor.description]\n",
    "\n",
    "        # Open the output CSV file for writing.\n",
    "        OutputcsvFile = csv.writer(open(CSVOutputfilePath + CSVOutputfileName, 'w', newline=''),\n",
    "                             delimiter=',', lineterminator='\\r\\n',\n",
    "                             quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "\n",
    "        # Adding header row and SQL data to the CSV file.\n",
    "        OutputcsvFile.writerow(headers_Row)\n",
    "        OutputcsvFile.writerows(resultData)\n",
    "        #print(resultData)\n",
    "        print(\"File created successfully.\")\n",
    "\n",
    "    except psycopg2.DatabaseError as e:\n",
    "        print(\"File creation unsuccessful.\")\n",
    "        quit()\n",
    "\n",
    "    finally:\n",
    "        connect_postgres.close()\n",
    "\n",
    "else:\n",
    "    print(\"File creation unsuccessful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547d49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
